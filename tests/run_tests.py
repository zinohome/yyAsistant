#!/usr/bin/env python3
"""
Test execution script for voice chat functionality
"""
import subprocess
import sys
import os
from pathlib import Path

def run_manual_tests():
    """Execute manual test checklist"""
    print("üß™ Starting Manual Test Execution...")
    print("=" * 50)
    
    # Check environment
    print("1. Environment Setup and Validation")
    print("   - Backend service: http://192.168.66.209:9800")
    print("   - Frontend service: http://192.168.66.209:8050")
    print("   - Browser permissions: microphone required")
    print("   - Audio devices: speakers/headphones")
    print()
    
    # Manual test checklist
    checklist_items = [
        "Text Chat Scenario:",
        "  - Basic text input and button states",
        "  - Empty input validation",
        "  - Long text processing with TTS segmentation",
        "",
        "Voice Recording Scenario:",
        "  - Recording button state transitions",
        "  - Microphone permission handling",
        "  - STT conversion and SSE triggering",
        "",
        "Real-time Dialogue Scenario:",
        "  - Dialogue initialization",
        "  - Control buttons (mute/stop)",
        "  - Continuous conversation",
        "",
        "Button State Matrix:",
        "  - IDLE ‚Üí TEXT_PROCESSING ‚Üí IDLE",
        "  - IDLE ‚Üí RECORDING ‚Üí VOICE_PROCESSING ‚Üí IDLE",
        "  - Concurrent operation blocking",
        "",
        "Error Handling:",
        "  - Network disconnect recovery",
        "  - SSE timeout handling",
        "  - Audio device errors"
    ]
    
    for item in checklist_items:
        print(f"   {item}")
    
    print("\n‚úÖ Manual test checklist completed")
    print("üìù Record results in TEST_EXECUTION_REPORT.md")

def run_automated_tests():
    """Execute automated test suite"""
    print("\nü§ñ Starting Automated Test Execution...")
    print("=" * 50)
    
    # Install dependencies
    print("Installing test dependencies...")
    try:
        subprocess.run([
            sys.executable, "-m", "pip", "install", "-r", "tests/requirements.txt"
        ], check=True, cwd=".")
        print("‚úÖ Dependencies installed")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install dependencies: {e}")
        return False
    
    # Install Playwright browsers
    print("Installing Playwright browsers...")
    try:
        subprocess.run([
            sys.executable, "-m", "playwright", "install", "chromium"
        ], check=True)
        print("‚úÖ Playwright browsers installed")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install Playwright browsers: {e}")
        return False
    
    # Run pytest
    print("Running automated tests...")
    try:
        result = subprocess.run([
            sys.executable, "-m", "pytest", "tests/", "-v", 
            "--html=reports/test_report.html", 
            "--self-contained-html",
            "--cov=yyAsistant",
            "--cov-report=html",
            "--cov-report=term"
        ], cwd=".")
        
        if result.returncode == 0:
            print("‚úÖ All automated tests passed")
            return True
        else:
            print("‚ùå Some automated tests failed")
            return False
            
    except Exception as e:
        print(f"‚ùå Failed to run automated tests: {e}")
        return False

def generate_test_report():
    """Generate comprehensive test report"""
    print("\nüìä Generating Test Report...")
    print("=" * 50)
    
    report_content = f"""# Test Execution Report

**Date**: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Environment**: Voice Chat Testing
**Test Framework**: Playwright + pytest

## Test Results Summary

### Manual Tests
- [ ] Environment setup validation
- [ ] Text chat scenario testing
- [ ] Voice recording scenario testing  
- [ ] Real-time dialogue scenario testing
- [ ] Button state matrix validation
- [ ] Error handling testing

### Automated Tests
- [ ] Text chat automated tests
- [ ] Voice recording automated tests
- [ ] Real-time dialogue automated tests
- [ ] Button state matrix tests
- [ ] Error handling tests
- [ ] Performance tests

## Performance Metrics
- Text response time: < 3 seconds
- Recording processing time: < 5 seconds
- Real-time dialogue latency: < 2 seconds
- Audio quality clarity: > 90%

## Issues Found
(To be filled during test execution)

## Recommendations
(To be filled based on test results)

## Test Coverage
- Code coverage: (Generated by pytest-cov)
- Critical path coverage: (Manual verification)

## Next Steps
1. Review test results
2. Address any failing tests
3. Update test cases based on findings
4. Schedule regular test execution
"""
    
    with open("docs/TEST_EXECUTION_REPORT.md", "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print("‚úÖ Test report generated: docs/TEST_EXECUTION_REPORT.md")

def main():
    """Main test execution function"""
    print("üöÄ Voice Chat Comprehensive Testing")
    print("=" * 50)
    
    # Change to project directory
    os.chdir(Path(__file__).parent.parent)
    
    # Run manual tests
    run_manual_tests()
    
    # Run automated tests
    automated_success = run_automated_tests()
    
    # Generate report
    generate_test_report()
    
    if automated_success:
        print("\nüéâ All tests completed successfully!")
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Check the report for details.")
        sys.exit(1)

if __name__ == "__main__":
    main()